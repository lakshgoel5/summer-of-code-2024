# -*- coding: utf-8 -*-
"""timeseries1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/166rkvlHbJKTM25KknfUbjgkj34qLMe79

#Upload data
"""

#! pip install kaggle

from google.colab import drive
drive.mount('/content/drive')

!mkdir -p ~/.kaggle

! cp /content/drive/MyDrive/Kaggle/kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets list

#!kaggle competitions download -c store-sales-time-series-forecasting -p /content/drive/MyDrive/Kaggle

cd /content/drive/MyDrive/Kaggle

!mkdir timeseries

!pwd

!ls

!cd timeseries

!pwd

!cd /content/drive/MyDrive/Kaggle/timeseries

#! unzip /content/drive/MyDrive/Kaggle/timeseries/store-sales-time-series-forecasting.zip

!pwd

cd /content/drive/MyDrive/Kaggle/timeseries/

!pwd

#! unzip /content/drive/MyDrive/Kaggle/timeseries/store-sales-time-series-forecasting.zip

import pandas as pd
# for array computations and loading data
import numpy as np
import seaborn as sns
# for building linear regression models and preparing data
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# for building and training neural networks
import tensorflow as tf


# reduce display precision on numpy arrays
np.set_printoptions(precision=2)

# suppress warnings
tf.get_logger().setLevel('ERROR')
tf.autograph.set_verbosity(0)



"""#Looking at data"""

df_train=pd.read_csv('train.csv')
df_oil=pd.read_csv('oil.csv')
df_stores=pd.read_csv('stores.csv')
df_transactions=pd.read_csv('transactions.csv')
df_holidays=pd.read_csv('holidays_events.csv')

df_oil

df_stores

df_transactions

df_holidays

df_train.isna().sum()

df_transactions.isna().sum()

df_stores.isna().sum()

df_holidays.isna().sum()

df_oil.isna().sum()

df_oil.info()

df_train.info()

df_train

df_train['family'].unique()

"""#Old Implementation"""

one_hot = pd.get_dummies(df_train['family'])
# Drop column B as it is now encoded
df_train = df_train.drop('family',axis = 1)
# Join the encoded df
df_train = df_train.join(one_hot)
df_train

df_train['date'].nunique()

df_train['name_date']=df_train["date"].str[:4]
df_train["name_date"]

df_train["name_date"].nunique()

df_train['name_date_month']=df_train["date"].str[:8]
df_train["name_date_month"].nunique()

df_train.info()

df_train_mmyyyy=df_train
one_hot = pd.get_dummies(df_train_mmyyyy['name_date_month'])
# Drop column B as it is now encoded
df_train_mmyyyy = df_train_mmyyyy.drop('name_date_month',axis = 1)
df_train_mmyyyy = df_train_mmyyyy.join(one_hot)
df_train_mmyyyy

df_train_mmyyyy=df_train_mmyyyy.drop(['date','name_date'],axis=1)
df_train_mmyyyy

df_train_mmyyyy.info()

"""#Convert to datetime and implement trends"""

df_train

dtype = {
    'store_nbr': 'category',
    'family': 'category',
    'sales': 'float32',
    'onpromotion': 'uint64',
}
df_train= pd.read_csv(
    'train.csv',
    dtype=dtype,
    parse_dates=['date'],
    infer_datetime_format=True,
)
df_train.head()

df_train = df_train.set_index('date').to_period('D')
df_train

average_sales=df_train
average_sales = average_sales.set_index(['store_nbr', 'family'], append=True)
#why is this necessary to implement next line???
average_sales = average_sales.groupby('date').sum()['sales']
average_sales

average_sales["2013-01-01"]

"""##Time-step"""

import matplotlib.pyplot as plt

help(plt.subplot)

average_sales = average_sales.to_frame()
#Important

average_sales

b=np.arange(len(average_sales.index))
average_sales['Time']=b
average_sales

import seaborn as sns
fig, ax = plt.subplots()
fig.set_size_inches(20, 8.27)
ax.plot('Time', 'sales', data=average_sales, color='0.75')
ax = sns.regplot(x='Time', y='sales', data=average_sales, ci=None, scatter_kws=dict(color='0.25'))
ax.set_title('Time Plot for Sales');



"""##Lag-feature"""

average_sales['Lag_1'] = average_sales['sales'].shift(1)
average_sales

average_sales['Lag_1']= average_sales['Lag_1'].fillna(0)
average_sales

import seaborn as sns
fig, ax = plt.subplots()
fig.set_size_inches(20, 8.27)
ax.plot('Lag_1', 'sales', data=average_sales, color='0.75')
ax = sns.regplot(x='Lag_1', y='sales', data=average_sales, ci=None, scatter_kws=dict(color='0.25'))
ax.set_title('Time Plot for Sales');



"""#Train"""

plt.style.use("seaborn-whitegrid")
plt.rc("figure", autolayout=True, figsize=(11, 4))
plt.rc(
    "axes",
    labelweight="bold",
    labelsize="large",
    titleweight="bold",
    titlesize=14,
    titlepad=10,
)
plot_params = dict(
    color="0.75",
    style=".-",
    markeredgecolor="0.25",
    markerfacecolor="0.25",
    legend=False,
)

"""##Time-step"""

from sklearn.linear_model import LinearRegression

# Training data
X_1 = average_sales.loc[:, ['Time']]  # features
y_1 = average_sales.loc[:, 'sales']  # target

# Train the model
model_1 = LinearRegression()
model_1.fit(X_1, y_1)

# Store the fitted values as a time series with the same time index as
# the training data
y_pred_1 = pd.Series(model_1.predict(X_1), index=X_1.index)
ax = y_1.plot(**plot_params)
ax = y_pred_1.plot(ax=ax, linewidth=3)
ax.set_title('Time Plot of Tunnel Traffic');



"""##Lag"""

from sklearn.linear_model import LinearRegression

X_2 = average_sales.loc[:, ['Lag_1']]
y_2 = average_sales.loc[:, 'sales']  # create the target
y_2, X_2 = y_2.align(X_2, join='inner')  # drop corresponding values in target

model = LinearRegression()
model.fit(X_2, y_2)
y_pred_2=pd.Series(model.predict(X_2), index=X_2.index)
ax = y_2.plot(**plot_params)
ax = y_pred_2.plot(ax=ax, linewidth=3)
ax.set_title('Time Plot of Tunnel Traffic');

"""Fitting decent enough"""



"""#Trends (a fail)"""

moving_average = average_sales["sales"].rolling(
    window=400,       # 365-day window
    center=True,      # puts the average at the center of the window
    min_periods=200,  # choose about half the window size
).mean()              # compute the mean (could also do median, std, min, max, ...)

ax = average_sales["sales"].plot(style=".", color="0.7")
moving_average.plot(
    ax=ax, linewidth=3, title="Time Plot of sales", legend=False,
);
#Also plotting Prediction of time-step
y_pred_1.plot(ax=ax, linewidth=3)

"""Linear Regression model very close to moving mean"""

from statsmodels.tsa.deterministic import DeterministicProcess

dp = DeterministicProcess(
    index=average_sales.index,  # dates from the training data
    constant=True,       # dummy feature for the bias (y_intercept)
    order=1,             # the time dummy (trend)
    drop=True,           # drop terms if necessary to avoid collinearity
)
X_fore = dp.out_of_sample(steps=30)
b=np.arange(len(X_fore.index))
X_fore['Time']=b
X_fore.head()
#y_fore_1 = pd.Series(model_1.predict(X_fore), index=X_fore.index)

#y_fore_1.head()

ax = average_sales["2005-05":].plot(title="Tunnel Traffic - Linear Trend Forecast", **plot_params)
ax = y_pred_1["2005-05":].plot(ax=ax, linewidth=3, label="Trend")
ax = y_fore.plot(ax=ax, linewidth=3, label="Trend Forecast", color="C3")
_ = ax.legend()

"""#Seasonality"""

def seasonal_plot(X, y, period, freq, ax=None):
    if ax is None:
        _, ax = plt.subplots()
    palette = sns.color_palette("husl", n_colors=X[period].nunique(),)
    ax = sns.lineplot(
        x=freq,
        y=y,
        hue=period,
        data=X,
        ci=False,
        ax=ax,
        palette=palette,
        legend=False,
    )
    ax.set_title(f"Seasonal Plot ({period}/{freq})")
    for line, name in zip(ax.lines, X[period].unique()):
        y_ = line.get_ydata()[-1]
        ax.annotate(
            name,
            xy=(1, y_),
            xytext=(6, 0),
            color=line.get_color(),
            xycoords=ax.get_yaxis_transform(),
            textcoords="offset points",
            size=14,
            va="center",
        )
    return ax
def plot_periodogram(ts, detrend='linear', ax=None):
    from scipy.signal import periodogram
    fs = pd.Timedelta("365D") / pd.Timedelta("1D")
    freqencies, spectrum = periodogram(
        ts,
        fs=fs,
        detrend=detrend,
        window="boxcar",
        scaling='spectrum',
    )
    if ax is None:
        _, ax = plt.subplots()
    ax.step(freqencies, spectrum, color="purple")
    ax.set_xscale("log")
    ax.set_xticks([1, 2, 4, 6, 12, 26, 52, 104])
    ax.set_xticklabels(
        [
            "Annual (1)",
            "Semiannual (2)",
            "Quarterly (4)",
            "Bimonthly (6)",
            "Monthly (12)",
            "Biweekly (26)",
            "Weekly (52)",
            "Semiweekly (104)",
        ],
        rotation=30,
    )
    ax.ticklabel_format(axis="y", style="sci", scilimits=(0, 0))
    ax.set_ylabel("Variance")
    ax.set_title("Periodogram")
    return ax

average_sales_ori=average_sales

"""###For year 2017"""

average_sales=average_sales.loc['2017']
average_sales

plot_periodogram(average_sales.sales);

"""It's a weekly Periodism"""

X_seasonality = average_sales
X_seasonality["week"] = X_seasonality.index.week
X_seasonality["day"] = X_seasonality.index.dayofweek
X_seasonality["year"] = X_seasonality.index.year
seasonal_plot(X_seasonality, y='sales', period='week', freq='day');
X_seasonality["day"] = X_seasonality.index.dayofyear
seasonal_plot(X_seasonality, y="sales", period="year", freq="day");

"""On an average, More sales are on day 5,6 and 0. \\
Also, sales increases yearly
"""

average_sales

from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess

fourier = CalendarFourier(freq="M", order=4)  # 4 sin/cos pairs for "A"nnual seasonality

dp = DeterministicProcess(
    index=average_sales.index,
    constant=True,               # dummy feature for bias (y-intercept)
    order=1,                     # trend (order 1 means linear)
    seasonal=True,               # weekly seasonality (indicators)
    additional_terms=[fourier],  # annual seasonality (fourier)
    drop=True,                   # drop terms to avoid collinearity
)

X_fourier = dp.in_sample()

y_fourier=average_sales['sales'].copy()
model_f = LinearRegression().fit(X_fourier, y_fourier)
y_pred_f = pd.Series(
    model_f.predict(X_fourier),
    index=X_fourier.index,
    name='Fitted',
)

X_fore_f = dp.out_of_sample(steps=90)
y_fore_f = pd.Series(model_f.predict(X_fore_f), index=X_fore_f.index)

#y_pred_f = pd.Series(model_f.predict(X_fourier), index=X_fourier.index)
ax = y_fourier.plot(**plot_params, alpha=0.5, title="Average Sales", ylabel="sales")
ax = y_pred_f.plot(ax=ax, label="Seasonal")
ax = y_fore_f.plot(ax=ax, label="Seasonal")

ax.legend();

"""Very bad prediction"""

y_deseason = y_fourier - y_pred_f
fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, sharey=True, figsize=(10, 7))
ax1 = plot_periodogram(y_fourier, ax=ax1)
ax1.set_title("Product Sales Frequency Components")
ax2 = plot_periodogram(y_deseason, ax=ax2);
ax2.set_title("Deseasonalized");

"""Model works well on a particular year. But if we take entire data set, it fails. WHY??"""

df_holidays

df_holidays['locale'].unique()

holidays_events = pd.read_csv(
    "holidays_events.csv",
    dtype={
        'type': 'category',
        'locale': 'category',
        'locale_name': 'category',
        'description': 'category',
        'transferred': 'bool',
    },
    parse_dates=['date'],
    infer_datetime_format=True,
)
holidays_events = holidays_events.set_index('date').to_period('D')

"""Below, If I include local holidays also, I get 231 entries, but y_fourier has 227 entries. I tried but coludn't merge it. Help!!!"""

holidays = (
    holidays_events
    .query("locale in ['National', 'Regional']")
    .loc['2017':'2017-08-15', ['description']]
    .assign(description=lambda x: x.description.cat.remove_unused_categories())
)

display(holidays)

ax = y_deseason.plot(**plot_params)
plt.plot_date(holidays.index, y_deseason[holidays.index], color='C3')
ax.set_title('Holidays');

X_holidays = pd.get_dummies(holidays)

X_fou_holi = X_fourier.join(X_holidays, on='date').fillna(0.0)
X_fou_holi.info()

y_fourier=average_sales['sales'].copy()

model = LinearRegression().fit(X_fou_holi, y_fourier)
y_pred = pd.Series(
    model.predict(X_fou_holi),
    index=X_fou_holi.index,
    name='Fitted',
)

y_pred = pd.Series(model.predict(X_fou_holi), index=X_fou_holi.index)
ax = y_fourier.plot(**plot_params, alpha=0.5, title="Average Sales", ylabel="items sold")
ax = y_pred.plot(ax=ax, label="Seasonal")
ax=y_pred_f.plot(ax=ax,label="Old predciction")
ax.legend();

"""See the difference between blue and orange"""



"""Huh, Lot's of analysis in seasonality"""



"""#Cycles"""

df_train

"""#Hybrid"""

df_train_hybrid=pd.read_csv(
    'train.csv',
    usecols=['store_nbr', 'family', 'date', 'sales', 'onpromotion'],
    dtype={
        'store_nbr': 'category',
        'family': 'category',
        'sales': 'float32',
    },
    parse_dates=['date'],
    infer_datetime_format=True,
)
df_train_hybrid['date'] = df_train_hybrid.date.dt.to_period('D')
df_train_hybrid = df_train_hybrid.set_index(['store_nbr', 'family', 'date']).sort_index()

family_sales = (
    df_train_hybrid
    .groupby(['family', 'date'])
    .sum()
    .unstack('family') #made rows to columns
    #And this all comes under column sales only
    .loc['2017']
)
family_sales.head()

class BoostedHybrid:
    def __init__(self, model_1, model_2):
        self.model_1 = model_1
        self.model_2 = model_2
        self.y_columns = None

def fit(self, X_1, X_2, y):
    # YOUR CODE HERE: fit self.model_1
    self.model_1.fit(X_1,y)

    y_fit = pd.DataFrame(
        # YOUR CODE HERE: make predictions with self.model_1
        self.model_1.predict(X_1),
        index=X_1.index, columns=y.columns,
    )

    # YOUR CODE HERE: compute residuals
    y_resid = y-y_fit
    y_resid = y_resid.stack().squeeze() # wide to long

    # YOUR CODE HERE: fit self.model_2 on residuals
    self.model_2.fit(X_2, y_resid)

    # Save column names for predict method
    self.y_columns = y.columns
    # Save data for question checking
    self.y_fit = y_fit
    self.y_resid = y_resid


# Add method to class
BoostedHybrid.fit = fit

def predict(self, X_1, X_2):
    y_pred = pd.DataFrame(
        # YOUR CODE HERE: predict with self.model_1
        self.model_1.predict(X_1),
        index=X_1.index, columns=self.y_columns,
    )
    y_pred = y_pred.stack().squeeze()  # wide to long

    # YOUR CODE HERE: add self.model_2 predictions to y_pred
    y_pred += self.model_2.predict(X_2)

    return y_pred.unstack()  # long to wide


# Add method to class
BoostedHybrid.predict = predict

y = family_sales.loc[:, 'sales']
y.head()

dp = DeterministicProcess(index=y.index, order=1)
X_1 = dp.in_sample()

X_2 = family_sales.drop('sales', axis=1).stack()
#stack used to convert columns to rows
X_2

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()  #convert categorical labels into numeric labels.
X_2 = X_2.reset_index('family')
X_2['family'] = le.fit_transform(X_2['family'])

# Label encoding for seasonality
X_2["day"] = X_2.index.day
X_2

from xgboost import XGBRegressor
model = BoostedHybrid(LinearRegression(),XGBRegressor())

# YOUR CODE HERE: Fit and predict
model.fit(X_1, X_2, y)
y_pred = model.predict(X_1,X_2)

y_pred = y_pred.clip(0.0)

y_train, y_valid = y[:"2017-07-01"], y["2017-07-02":]
X1_train, X1_valid = X_1[: "2017-07-01"], X_1["2017-07-02" :]
X2_train, X2_valid = X_2.loc[:"2017-07-01"], X_2.loc["2017-07-02":]

# Some of the algorithms above do best with certain kinds of
# preprocessing on the features (like standardization), but this is
# just a demo.
model.fit(X1_train, X2_train, y_train)
y_fit = model.predict(X1_train, X2_train).clip(0.0)
y_pred = model.predict(X1_valid, X2_valid).clip(0.0)

families = y.columns[1:2]
axs = y.loc(axis=1)[families].plot(
    subplots=True, sharex=True, figsize=(11, 9), **plot_params, alpha=0.5,
)
_ = y_fit.loc(axis=1)[families].plot(subplots=True, sharex=True, color='C0', ax=axs)
_ = y_pred.loc(axis=1)[families].plot(subplots=True, sharex=True, color='C3', ax=axs)
for ax, family in zip(axs, families):
    ax.legend([])
    ax.set_ylabel(family)

from sklearn.linear_model import ElasticNet, Lasso, Ridge

# Model 2
from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.neural_network import MLPRegressor

# Boosted Hybrid

# YOUR CODE HERE: Try different combinations of the algorithms above
model = BoostedHybrid(
    model_1=LinearRegression(),
    model_2=KNeighborsRegressor(),
)

y_train, y_valid = y[:"2017-07-01"], y["2017-07-02":]
X1_train, X1_valid = X_1[: "2017-07-01"], X_1["2017-07-02" :]
X2_train, X2_valid = X_2.loc[:"2017-07-01"], X_2.loc["2017-07-02":]

# Some of the algorithms above do best with certain kinds of
# preprocessing on the features (like standardization), but this is
# just a demo.
model.fit(X1_train, X2_train, y_train)
y_fit = model.predict(X1_train, X2_train).clip(0.0)
y_pred = model.predict(X1_valid, X2_valid).clip(0.0)

families = y.columns[0:6]
axs = y.loc(axis=1)[families].plot(
    subplots=True, sharex=True, figsize=(11, 9), **plot_params, alpha=0.5,
)
_ = y_fit.loc(axis=1)[families].plot(subplots=True, sharex=True, color='C0', ax=axs)
_ = y_pred.loc(axis=1)[families].plot(subplots=True, sharex=True, color='C3', ax=axs)
for ax, family in zip(axs, families):
    ax.legend([])
    ax.set_ylabel(family)

dp = DeterministicProcess(index=y.index, order=1)
X_1 = dp.in_sample()

"""Few families are giving very bad predictions. So Im checking correlation of onpromotion with sales for these 3"""

family_sales

y_extra = y['BABY CARE']
y_extra

dp = DeterministicProcess(index=y.index, order=1)
X_1 = dp.in_sample()

model = LinearRegression().fit(X_1, y_extra)
y_pred = pd.Series(
    model.predict(X_1),
    index=X_1.index,
    name='Fitted',
)

X_fore = dp.out_of_sample(steps=90)
y_fore = pd.Series(model.predict(X_fore), index=X_fore.index)

#y_pred_f = pd.Series(model_f.predict(X_fourier), index=X_fourier.index)
ax = y_extra.plot(**plot_params, alpha=0.5, title="Average Sales", ylabel="sales")
ax = y_fore.plot(ax=ax, label="forecast")

ax = y_pred.plot(ax=ax, label="predict")

ax.legend();

X_3 = family_sales.loc[:, 'onpromotion']
#stack used to convert columns to rows
X_3=X_3["BABY CARE"]
X_3

y_resid = y_extra-y_pred
y_resid

ax = y_resid.plot(**plot_params)
plt.plot_date(X_3.index, y_resid[X_3.index], color='C3')
ax.set_title('Correlation for BABY CARE');

model = LinearRegression().fit(X_1, y_resid)
y_pred_1 = pd.Series(
    model.predict(X_1),
    index=X_1.index,
    name='Fitted',
)

# X_fore = dp.out_of_sample(steps=90)
# y_fore = pd.Series(model.predict(X_fore), index=X_fore.index)

#y_pred_f = pd.Series(model_f.predict(X_fourier), index=X_fourier.index)
ax = y_resid.plot(**plot_params, alpha=0.5, title="Average Sales", ylabel="sales")
#ax = y_fore.plot(ax=ax, label="forecast")

ax = y_pred_1.plot(ax=ax, label="predict")

ax.legend();

y_pred_1

y=y_pred+y_pred_1
ax = y_extra.plot(**plot_params, alpha=0.5, title="Average Sales", ylabel="sales")
#ax = y_fore.plot(ax=ax, label="forecast")

ax = y.plot(ax=ax, label="predict")

y_resid_2=y_extra-y
y_resid

